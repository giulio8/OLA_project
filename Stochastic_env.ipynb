{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic environment (First requirement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import Configuration as config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic environment \n",
    "The stochastic environment takes as \"input\" the action of the agent which corresponds to the bid. Then it simulates the distribution from which the other bids are sampled and the probability conversion (prob. of buying given a price -> demand curve normalized). Eventually, it outputs the reward associated with  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pricing_stochastic_env():\n",
    "    def __init__(self, probability_conversion):\n",
    "        #self.rewards \n",
    "        self.probability_conversion = probability_conversion\n",
    "\n",
    "    def round(self, p_t, n_t):\n",
    "        d_t = np.random.binomial(n_t, self.conversion_probability(p_t))\n",
    "        r_t = (p_t - self.cost) * d_t      # the reward is equal to the profit given by (price-cost)*expected demand (sampled)\n",
    "        return d_t, r_t\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bidding_stochastic_env():\n",
    "    def __init__(self, B, T, lambdas):\n",
    "        self.B = B\n",
    "        self.T = T      \n",
    "        #self.rho = B/T\n",
    "        self.lambdas = lambdas\n",
    "        self.n_slots = len(lambdas)\n",
    "        self.ctrs = np.ones(T)    # for simplicity we keep them all equal to 1\n",
    "\n",
    "    def get_winners(self, bids):\n",
    "        adv_values = self.ctrs*bids\n",
    "        adv_ranking = np.argsort(adv_values)        # array with the index of adv_values sorted in increasing order\n",
    "        winners = adv_ranking[-self.n_slots:]       # taking the last n_slots indexes, i.e. the indexes of the highest values\n",
    "        winners_values = adv_values[winners]\n",
    "        return winners, winners_values\n",
    "        \n",
    "    def get_payments_per_click(self, values):\n",
    "        adv_ranking = np.argsort(values)    # sorting the values (q param times bid) in increasing order\n",
    "        for i in range(self.n_slots):\n",
    "            payment = values[adv_ranking[-i]]/self.ctrs[adv_ranking[-i-1]]  # generalized second price auctions\n",
    "        return payment.round(2)\n",
    "\n",
    "    def round(self, bids):\n",
    "        # bids contains all bids, including mine which is stored in the first position\n",
    "        winners, values = self.get_winners(bids)        # winners are the indexes of the highest values in the array\n",
    "        payments_per_click = self.get_payments_per_click(values)\n",
    "        return winners, payments_per_click\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pricing algorithm\n",
    "Build a pricing strategy using the continuous set of prices $p \\in [0,1]$ and Gaussian Processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from lab session 3\n",
    "class RBFGaussianProcess:\n",
    "    def __init__(self, scale=1, reg=1e-2):\n",
    "        self.scale = scale \n",
    "        self.reg = reg\n",
    "        self.k_xx_inv = None\n",
    "\n",
    "    def rbf_kernel_incr_inv(self, B, C, D):\n",
    "        temp = np.linalg.inv(D - C @ self.k_xx_inv @ B)\n",
    "        block1 = self.k_xx_inv + self.k_xx_inv @ B @ temp @ C @ self.k_xx_inv\n",
    "        block2 = - self.k_xx_inv @ B @ temp\n",
    "        block3 = - temp @ C @ self.k_xx_inv\n",
    "        block4 = temp\n",
    "        res1 = np.concatenate((block1, block2), axis=1)\n",
    "        res2 = np.concatenate((block3, block4), axis=1)\n",
    "        res = np.concatenate((res1, res2), axis=0)\n",
    "        return res\n",
    "\n",
    "    def rbf_kernel(self, a, b):\n",
    "        a_ = a.reshape(-1, 1)\n",
    "        b_ = b.reshape(-1, 1)\n",
    "        output = -1 * np.ones((a_.shape[0], b_.shape[0]))\n",
    "        for i in range(a_.shape[0]):\n",
    "            output[i, :] = np.power(a_[i] - b_, 2).ravel()\n",
    "        return np.exp(-self.scale * output)\n",
    "    \n",
    "    def fit(self, x=np.array([]), y=np.array([])):\n",
    "        x,y = np.array(x),np.array(y)\n",
    "        if self.k_xx_inv is None:\n",
    "            self.y = y.reshape(-1,1)\n",
    "            self.x = x.reshape(-1,1)\n",
    "            k_xx = self.rbf_kernel(self.x, self.x) + self.reg * np.eye(self.x.shape[0])\n",
    "            self.k_xx_inv = np.linalg.inv(k_xx)\n",
    "        else:\n",
    "            B = self.rbf_kernel(self.x, x)\n",
    "            self.x = np.vstack((self.x, x))\n",
    "            self.y = np.vstack((self.y, y))\n",
    "            self.k_xx_inv = self.rbf_kernel_incr_inv(B, B.T, np.array([1 + self.reg]))\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, x_predict):\n",
    "        k = self.rbf_kernel(x_predict, self.x)\n",
    "\n",
    "        mu_hat = k @ self.k_xx_inv @ self.y\n",
    "        sigma_hat = 1 - np.diag(k @ self.k_xx_inv @ k.T)\n",
    "\n",
    "        return mu_hat.ravel(), sigma_hat.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing the Gaussian Processes in our agent:\n",
    "- recall to normalize the input -> in the continuous set $[0,1]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from lab session 3 as well\n",
    "class pricing_agent():\n",
    "    def __init__(self, T, discretization=100):\n",
    "        self.T = T\n",
    "        self.arms = np.linspace(0, 1, discretization)\n",
    "        self.gp = RBFGaussianProcess(scale=2).fit()\n",
    "        self.a_t = None\n",
    "        self.action_hist = np.array([])\n",
    "        self.reward_hist = np.array([])\n",
    "        self.mu_t = np.zeros(discretization)\n",
    "        self.sigma_t = np.zeros(discretization)\n",
    "        self.gamma = lambda t: np.log(t+1)**2 \n",
    "        self.beta = lambda t: 1 + 0.5*np.sqrt(2 * (self.gamma(t) + 1 + np.log(T)))      # from PAPER LINKED IGP-UCB ALGORITHM\n",
    "        self.N_pulls = np.zeros(discretization)\n",
    "        self.t = 0\n",
    "    \n",
    "    def pull_arm(self):\n",
    "        self.mu_t, self.sigma_t = self.gp.predict(self.arms) \n",
    "        ucbs = self.mu_t + self.beta(t) * self.sigma_t\n",
    "        self.a_t = np.argmax(ucbs)\n",
    "        return self.arms[self.a_t]\n",
    "    \n",
    "    def update(self, r_t):\n",
    "        self.N_pulls[self.a_t] += 1\n",
    "        self.action_hist = np.append(self.action_hist, self.arms[self.a_t])\n",
    "        self.reward_hist = np.append(self.reward_hist, r_t)\n",
    "        self.gp = self.gp.fit(self.arms[self.a_t], r_t)\n",
    "        self.t += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidding algorithms\n",
    "Consider a sequence of generalized second-price auctions. Build two learning algorithms to deal with the bidding problem:\n",
    "- a primal-dual algorithm for truthful auctions\n",
    "- a UCB-like algorithm\n",
    "\n",
    "Generalized second-price auctions: each advertiser $a$ pays $p_a = \\dfrac{q_{a+1}}{q_a} b_{a+1}$ if the ad is clicked. This has to be "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class primal_dual_agent():\n",
    "    def __init__(self, B, T, eta) -> None:\n",
    "        pass\n",
    "    \n",
    "    def action():\n",
    "        # choose price to bid\n",
    "        pass\n",
    "    \n",
    "    def update():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be implemented following the algorithm in the slide 18 from slide package 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UCB_agent():\n",
    "    def __init__(self, B, T, eta=0.1) -> None:\n",
    "        self.budget = B     # budget\n",
    "        self.T = T          # number of rounds\n",
    "        self.eta = eta      # learning rate\n",
    "    \n",
    "    def action():\n",
    "        # choose price to bid \n",
    "        pass\n",
    "    \n",
    "    def update():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General framework to be modeled\n",
    "Recall that:\n",
    "- GPUCB1 works on the continuous domain [0,1]\n",
    "- the UCB-like algorithm for bidding works on the discretized set of bids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing parameters\n",
    "ITERATIONS = config.ITERATIONS\n",
    "AUCTIONS = config.AUCTIONS\n",
    "N_USERS = config.N_USERS\n",
    "N_ADVERTISERS = config.N_ADVERTISERS    # number of companies that compete for slot auctions, including myself\n",
    "NUMBER_OF_ARMS = config.NUMBER_OF_ARMS    # needed for the UCB algorithm\n",
    "PRICES = config.NUMBER_OF_ARMS    # actual arms of the ucb algorithm\n",
    "BUGDET = config.BUGDET\n",
    "NUMBER_OF_SLOTS = config.NUMBER_OF_SLOTS\n",
    "LAMBDAS = config.LAMBDAS\n",
    "\n",
    "\n",
    "conversion_probability = lambda p: 1-p/20\n",
    "pricing_agent = pricing_agent(ITERATIONS, 100)\n",
    "bidding_agent = UCB_agent(BUGDET, ITERATIONS)\n",
    "\n",
    "\n",
    "pse = pricing_stochastic_env(conversion_probability)\n",
    "bse = bidding_stochastic_env(B=BUGDET, T=ITERATIONS, lambdas=LAMBDAS)\n",
    "\n",
    "my_valuation = 0.8      # randomly chosen\n",
    "utilities = np.array([])\n",
    "my_bids = np.array([])\n",
    "my_payments = np.array([])\n",
    "total_wins = 0\n",
    "\n",
    "\n",
    "for round in range(ITERATIONS):\n",
    "    #p_t = pricing_agent.pull_arm()    # pricing agent choose a price p for the product\n",
    "\n",
    "    for auction in range(AUCTIONS):\n",
    "        my_bid = bidding_agent.action()    # bidding agent decides how much to bid \n",
    "        other_bids = np.random.uniform(0, 1, size = (N_ADVERTISERS)) # size = (N_ADVERTISERS, N_USERS) \n",
    "        all_bids = np.append(my_bid, other_bids)    # all bids, including mine in first position\n",
    "        winners, payments_per_click = bse.round(bids=all_bids)    # somebody wins the auction\n",
    "        m_t = other_bids.max()    # maximum bid among the other advertisers\n",
    "        my_win = 0 if 0 in winners else 1 \n",
    "        f_t, c_t = (my_valuation-m_t)*my_win, m_t*my_win\n",
    "        bidding_agent.update(f_t, c_t)\n",
    "        # logging\n",
    "        utilities = np.append(utilities, f_t)\n",
    "        my_bids = np.append(my_bids, my_bid)\n",
    "        my_payments = np.append(my_payments, c_t)\n",
    "        total_wins+=my_win\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
