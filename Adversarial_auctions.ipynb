{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#!pip install scipy\n",
    "from scipy import stats\n",
    "from scipy import optimize\n",
    "from math import sin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Auction:\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        pass\n",
    "\n",
    "    def get_winners(self, bids):\n",
    "        pass\n",
    "\n",
    "    def get_payments_per_click(self, winners, values, bids):\n",
    "        pass\n",
    "\n",
    "    def round(self, bids):\n",
    "        winners, values = self.get_winners(bids) # allocation mechanism!\n",
    "        payments_per_click = self.get_payments_per_click(winners, values, bids)\n",
    "        return winners, payments_per_click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FirstPriceAuction(Auction):\n",
    "    def __init__(self, ctrs):\n",
    "        self.ctrs = ctrs\n",
    "        self.n_adv = len(self.ctrs)\n",
    "\n",
    "    def get_winners(self, bids):\n",
    "        adv_values = self.ctrs*bids\n",
    "        adv_ranking = np.argsort(adv_values)\n",
    "        winner = adv_ranking[-1]\n",
    "        return winner, adv_values\n",
    "\n",
    "    def get_payments_per_click(self, winners, values, bids):\n",
    "        payment = bids[winners]\n",
    "        return payment.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's configure the parameters to have the same values of the other parts of the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Configuration parameters\n",
    "ITERATIONS = 1000\n",
    "AUCTIONS = 100\n",
    "N_USERS = 100\n",
    "N_ADVERTISERS = 10    # number of companies that compete for slot auctions, including myself\n",
    "NUMBER_OF_ARMS = 100    # needed for the UCB algorithm\n",
    "PRICES = np.linspace(0, 1, NUMBER_OF_ARMS)    # actual arms of the ucb algorithm\n",
    "BUGDET = 1000 # I know it's mispelled but i found it like this in the other file so i kept it like this\n",
    "NUMBER_OF_SLOTS = 10\n",
    "\n",
    "lambda_fun_param = lambda s: 1/(s+(0.3))       # probability of the ad being seen given the position s ->  0.5 for first position, 0.33 for second, 0.25 for third, etc...\n",
    "LAMBDAS = np.array([lambda_fun_param(i) for i in range(1, NUMBER_OF_SLOTS+1)])    # array of lambda values (for each slot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pattern definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Adversarial Bidders\n",
    "#### interest !!\n",
    "my_valuation = 0.6 #used in c\n",
    "rho = BUGDET/N_USERS\n",
    "\n",
    "# non-trivial scenario: competitors sample bids from a uniform with range varying over time\n",
    "pattern = lambda t: 1-np.abs(np.sin(5*t/N_USERS))\n",
    "other_bids = np.array([np.random.uniform(0, pattern(t), size = N_ADVERTISERS) for t in range(N_USERS)]).T\n",
    "# I assume that competitors may have a larger budget than mine, but they may\n",
    "# not deplete it.\n",
    "\n",
    "m_t = other_bids.max(axis=0)\n",
    "\n",
    "plt.plot(m_t)\n",
    "plt.title('Expected maximum bid')\n",
    "plt.xlabel('$t$')\n",
    "plt.ylabel('$m_t$')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clairvoyant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_bids = np.linspace(0,1,11)\n",
    "win_probabilities = np.array([sum(b > m_t)/N_USERS for b in available_bids])\n",
    "## Linear Program\n",
    "#linprog is a wayto optimize the function and the bid\n",
    "c = -(my_valuation-available_bids)*win_probabilities\n",
    "A_ub = [available_bids*win_probabilities]\n",
    "b_ub = [rho]\n",
    "A_eq = [np.ones(len(available_bids))]\n",
    "b_eq = [1]\n",
    "res = optimize.linprog(c, A_ub=A_ub, b_ub=b_ub, A_eq=A_eq, b_eq=b_eq, bounds=(0,1))\n",
    "gamma = res.x\n",
    "expected_clairvoyant_utilities = [-res.fun for u in range(N_USERS)]\n",
    "expected_clairvoyant_bids = [sum(available_bids*gamma*win_probabilities) for u in range(N_USERS)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalized Multiplicative Pacing for Non-Truthful Auctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here, we will assume a **full-feedback** setting. In auctions, full-feedback is equivalent of knowing the maximum bid $m_t$ that won the auction (of course, **after** the auction). Moreover, bids will be **discretized** into a finite set of actions.\n",
    "Full feedback = You know th bid of each competitor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will leverage a full-feedback, adversarial learner such as Hedge (see Lab 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HedgeAgent:\n",
    "    def __init__(self, narms, learning_rate): #ho tolto il numero di slot da questa classe per tenere solo narms\n",
    "        self.narms = narms   #number of possible bids\n",
    "        self.learning_rate = learning_rate #supposing it's the rate at which the algorithm progress\n",
    "        self.weights = np.ones(narms) #weight == proportionnal to the probabilty\n",
    "        self.x_t = np.ones(narms)/narms #probability of a bid to be played\n",
    "        self.a_t = None # bid choice done during the round\n",
    "        self.t = 0\n",
    "\n",
    "    def pull_arm(self): #choose which arm to play\n",
    "        self.x_t = self.weights/sum(self.weights)\n",
    "        self.a_t = np.random.choice(np.arange(self.narms), p=self.x_t)\n",
    "        return self.a_t\n",
    "\n",
    "    def update(self, l_t): #update the weights\n",
    "        self.weights *= np.exp(-self.learning_rate*l_t)\n",
    "        self.t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFMultiplicativePacingAgent:\n",
    "    def __init__(self, bids_set, valuation, budget, T, eta):\n",
    "        self.bids_set = bids_set #available choices\n",
    "        self.narms = len(bids_set) #nuber of bid choices\n",
    "        self.hedge = HedgeAgent(self.narms, np.sqrt(np.log(self.narms)/T)) #qui ci va narms o nslots?? ma come learning rate non ci andrebbe eta??\n",
    "        self.valuation = valuation #what you earn, ctr*profit_per_click\n",
    "        self.budget = budget\n",
    "        self.eta = eta #learning rate\n",
    "        self.T = T  #number of rounds\n",
    "        self.rho = self.budget/self.T #bid limit\n",
    "        self.lmbd = 1 #pacing multiplier, when we spend more than rho it increses otherwise we decrease it\n",
    "        self.t = 0\n",
    "\n",
    "    def bid(self):\n",
    "        if self.budget < 1:\n",
    "            return 0\n",
    "        return self.bids_set[self.hedge.pull_arm()]\n",
    "\n",
    "    def update(self, f_t, c_t, m_t):\n",
    "        # update hedge\n",
    "        f_t_full = np.array([(self.valuation-b)*int(b >= m_t) for b in self.bids_set])\n",
    "        c_t_full = np.array([b*int(b >= m_t) for b in self.bids_set])\n",
    "        L = f_t_full - self.lmbd*(c_t_full-self.rho)\n",
    "        range_L = 2+(1-self.rho)/self.rho\n",
    "        self.hedge.update((2-L)/range_L) # hedge needs losses in [0,1]\n",
    "        # update lagrangian multiplier\n",
    "        self.lmbd = np.clip(self.lmbd-self.eta*(self.rho-c_t),\n",
    "                            a_min=0, a_max=1/self.rho)\n",
    "        # update budget\n",
    "        self.budget -= c_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 1/np.sqrt(N_USERS)  # Learning rate from theory\n",
    "\n",
    "# Initializing the agent and auction\n",
    "agent = FFMultiplicativePacingAgent(bids_set=available_bids,\n",
    "                                    valuation=my_valuation,\n",
    "                                    budget=BUGDET,\n",
    "                                    T=N_USERS,\n",
    "                                    eta=eta)\n",
    "\n",
    "auction = FirstPriceAuction(np.ones(N_ADVERTISERS + 1))  # Auction setup\n",
    "\n",
    "# Arrays to store results\n",
    "utilities = np.array([])  # Utility gained in each auction\n",
    "my_bids = np.array([])  # Bids placed by the agent\n",
    "my_payments = np.array([])  # Payments made by the agent\n",
    "total_wins = 0  # Counter for total wins\n",
    "\n",
    "# Running the auction process\n",
    "np.random.seed(1)  # Seed for reproducibility\n",
    "\n",
    "for u in range(N_USERS):\n",
    "    # Agent places a bid\n",
    "    my_bid = agent.bid()\n",
    "\n",
    "    # Gather all bids for this auction\n",
    "    bids = np.append(my_bid, other_bids[:, u].ravel())\n",
    "    m_t_new = np.max(bids)\n",
    "\n",
    "    # Determine winners and payments\n",
    "    winners, payments_per_click = auction.round(bids=bids)\n",
    "\n",
    "    # Check if the agent won\n",
    "    my_win = int(winners == 0)  # Agent wins if winners is 0\n",
    "\n",
    "    # Calculate the utility and payment for the agent\n",
    "    f_t = (my_valuation - m_t_new) * my_win  # Utility when the agent wins\n",
    "    c_t = m_t_new * my_win  # Payment if the agent wins\n",
    "\n",
    "    # Update the agent's learning based on the auction outcome\n",
    "    agent.update(f_t, c_t, m_t_new)\n",
    "\n",
    "    # Store the results\n",
    "    utilities = np.append(utilities, f_t)  # Append utility\n",
    "    my_bids = np.append(my_bids, my_bid)  # Append bid\n",
    "    my_payments = np.append(my_payments, c_t)  # Append payment\n",
    "    total_wins += my_win  # Increment total wins\n",
    "\n",
    "    cumulative_payments = np.cumsum(my_payments)\n",
    "\n",
    "    # Nicely formatted output to track progress\n",
    "    print(f\"\\nIteration {u}:\")  # New line for each iteration\n",
    "    print(f\"  My bid            : {my_bid:.2f}\")\n",
    "    print(f\"  All bids          : {bids}\")\n",
    "    print(f\"  Winners           : {winners}\")\n",
    "    print(f\"  My win            : {my_win}\")\n",
    "    print(f\"  m_t[{u}]          : {m_t_new:.2f}\")\n",
    "    print(f\"  c_t               : {c_t:.2f}\")\n",
    "    print(f\"  Total wins so far : {total_wins}\")\n",
    "    print(f\"  Current payment : {my_payments[u]}\")\n",
    "    print(f\"  Total paid so far : {cumulative_payments[u]}\")\n",
    "\n",
    "# Display total number of wins at the end\n",
    "print(f\"Total number of wins: {total_wins}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "graphical representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(my_bids)\n",
    "plt.xlabel('$t$')\n",
    "plt.ylabel('$b_t$')\n",
    "plt.title('Chosen Bids')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_payments = np.cumsum(my_payments)\n",
    "plt.plot(cumulative_payments)\n",
    "plt.xlabel('$t$')\n",
    "plt.ylabel('$\\sum c_t$')\n",
    "plt.axhline(BUGDET, color='red', label='Budget')\n",
    "plt.legend()\n",
    "plt.title('Cumulative Payments of Multiplicative Pacing')\n",
    "plt.show()\n",
    "\n",
    "## ATTENTION: The payments line looks fixed to 0 but it's not, it reaches something like 22 (we are watching just the first iteration out of 1000) but since the budget is 1000 it looks flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_regret = np.cumsum(expected_clairvoyant_utilities-utilities)\n",
    "plt.plot(cumulative_regret)\n",
    "plt.xlabel('$t$')\n",
    "plt.ylabel('$\\sum R_t$')\n",
    "plt.title('Cumulative Regret of Multiplicative Pacing')\n",
    "plt.show()\n",
    "\n",
    "## ATTENTION: The negative regret problem looks fixed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now doing multiple rounds to have a better idea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_regrets = []\n",
    "all_payments = []\n",
    "for i in range(ITERATIONS):\n",
    "    agent = FFMultiplicativePacingAgent(bids_set = available_bids,\n",
    "                                        valuation=my_valuation,\n",
    "                                        budget=BUGDET,\n",
    "                                        T=N_USERS,\n",
    "                                        eta=eta)\n",
    "\n",
    "    auction = FirstPriceAuction(np.ones(N_ADVERTISERS+1))\n",
    "    utilities = np.array([])\n",
    "    my_bids = np.array([])\n",
    "    my_payments = np.array([])\n",
    "\n",
    "    np.random.seed(i)\n",
    "    for u in range(N_USERS):\n",
    "        # interaction\n",
    "        my_bid = agent.bid()\n",
    "        bids = np.append(my_bid, other_bids[:, u].ravel())\n",
    "        winners, payments_per_click = auction.round(bids=bids)\n",
    "        my_win = int(winners==0)\n",
    "        f_t, c_t = (my_valuation-m_t[u])*my_win, m_t[u]*my_win\n",
    "        agent.update(f_t, c_t, m_t[u])\n",
    "        # logging\n",
    "        utilities = np.append(utilities, f_t)\n",
    "        my_payments = np.append(my_payments, c_t)\n",
    "    all_regrets.append(np.cumsum(expected_clairvoyant_utilities-utilities))\n",
    "    all_payments.append(np.cumsum(my_payments))\n",
    "\n",
    "avg_regret = np.array(all_regrets).mean(axis=0)\n",
    "std_regret = np.array(all_regrets).std(axis=0)\n",
    "\n",
    "avg_payments = np.array(all_payments).mean(axis=0)\n",
    "std_payments = np.array(all_payments).std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "graphical representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(n_users), avg_payments)\n",
    "plt.fill_between(np.arange(n_users), avg_payments-std_payments, avg_payments+std_payments, alpha=0.3)\n",
    "plt.xlabel('$t$')\n",
    "plt.ylabel('$\\sum c_t$')\n",
    "plt.axhline(B, color='red', label='Budget')\n",
    "plt.legend()\n",
    "plt.title('Cumulative Payments of Multiplicative Pacing')\n",
    "plt.show()\n",
    "\n",
    "## ATTENTION: I think this graph shows the average amount paid in 1 iteration compared to the total budget, so it looks very similar to the single iteration graph, maybe we should change it and show the sum instead of the avg so we can see among the 1000 iterations which is the cumulative expense compared to the budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(N_USERS), avg_regret)\n",
    "plt.fill_between(np.arange(N_USERS), avg_regret-std_regret, avg_regret+std_regret, alpha=0.3)\n",
    "plt.xlabel('$t$')\n",
    "plt.ylabel('$\\sum R_t$')\n",
    "plt.title('Cumulative Regret of Full-Feedback Multiplicative Pacing')\n",
    "plt.show()\n",
    "\n",
    "## ATTENTION: same reasoning that I did for the payments graph, maybe we should sow the total regret instead of the avg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
